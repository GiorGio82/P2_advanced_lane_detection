{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "%matplotlib qt\n",
    "\n",
    "camera_params = pickle.load( open( \"camera_calibration.p\", \"rb\" ) )\n",
    "mtx = camera_params['mtx']\n",
    "dist = camera_params['dist']\n",
    "rvecs = camera_params['rvecs']\n",
    "tvecs = camera_params['tvecs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img, mtx, dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist  \n",
    "\n",
    "def binary_sobelx(color_img,kernel_size=3,sx_thresh=(20, 100), gauss_blur=False, gauss_k_size = 3):\n",
    "    gray = cv2.cvtColor(np.copy(color_img), cv2.COLOR_RGB2GRAY)  \n",
    "    \n",
    "    if gauss_blur:\n",
    "        smoothed = gaussian_blur(gray,gauss_k_size)\n",
    "        sobelx = cv2.Sobel(smoothed, cv2.CV_64F, 1, 0,ksize=kernel_size) # Take the derivative in x\n",
    "    else:\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0,ksize=kernel_size) # Take the derivative in x\n",
    "\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    return sxbinary\n",
    "\n",
    "def sobel_mag_thresh(color_img, kernel_size=3, mag_thresh=(30, 100)):\n",
    "    \n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(np.copy(color_img), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # 2) Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    \n",
    "    # 3) Calculate the magnitude\n",
    "    mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scale_factor = np.max(mag)/255 \n",
    "    norm_mag = (mag/scale_factor).astype(np.uint8)     \n",
    "    \n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    binary_mag = np.zeros_like(norm_mag)\n",
    "    binary_mag[(norm_mag >= mag_thresh[0]) & (norm_mag <=mag_thresh[1])] = 1\n",
    "    \n",
    "    return binary_mag\n",
    "\n",
    "def binary_s_channel(color_img,s_thresh=(150, 255)):\n",
    "    \n",
    "    hls = cv2.cvtColor(np.copy(color_img), cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1    \n",
    "    \n",
    "    return s_binary\n",
    "\n",
    "def binary_r_channel(color_img,r_thresh=(200,255)):\n",
    "    img = np.copy(color_img)\n",
    "    #red channel\n",
    "    r_channel = img[:,:,0]\n",
    "    r_binary = np.zeros_like(r_channel)\n",
    "    r_binary[(r_channel >= r_thresh[0]) & (r_channel <= r_thresh[1])] = 1      \n",
    "    \n",
    "    return r_binary \n",
    "\n",
    "def binary_filters(s_x = True, bin_sx=0,s_mag=True, bin_s_mag=0, s_ch=True,bin_s_ch=0,r_ch=True,bin_r_ch=0):\n",
    "    \n",
    "    #init\n",
    "    if s_x == True:\n",
    "        binary_mask = np.zeros_like(bin_sx)\n",
    "    elif s_mag == True:\n",
    "        binary_mask = np.zeros_like(bin_s_mag)\n",
    "    elif s_ch == True:\n",
    "        binary_mask = np.zeros_like(bin_s_ch)\n",
    "    elif r_ch == True:\n",
    "        binary_mask = np.zeros_like(bin_r_ch)\n",
    "\n",
    "    #apply only specific filters\n",
    "    if (s_x == True) :\n",
    "        binary_mask[(bin_sx ==1) | (binary_mask ==1)] = 1                \n",
    "    if (s_mag == True):\n",
    "        binary_mask[(bin_s_mag ==1) | (binary_mask ==1)] = 1     \n",
    "    if (s_ch == True):\n",
    "        binary_mask[(bin_s_ch ==1) | (binary_mask ==1)] = 1\n",
    "    if (r_ch == True):\n",
    "        binary_mask[(bin_r_ch ==1) | (binary_mask ==1)] = 1 \n",
    " \n",
    "    return binary_mask\n",
    "\n",
    "def colors_and_gradients(warped):\n",
    "    bin_sobelx = binary_sobelx(warped,kernel_size=5,sx_thresh=(20, 100),gauss_blur=True)\n",
    "    bin_s_channel = binary_s_channel(warped,s_thresh=(150, 255))\n",
    "    bin_r_channel =  binary_r_channel(warped,r_thresh=(200,255))\n",
    "    bin_sobel_mag = sobel_mag_thresh(warped, kernel_size=5, mag_thresh=(30, 100)) \n",
    "\n",
    "    count_light_in_red_ch =  np.sum(bin_r_channel[:,:])\n",
    "\n",
    "    if count_light_in_red_ch > 150000:\n",
    "        binary_or_img = binary_filters(s_x = True, bin_sx = bin_sobelx,\n",
    "                                   s_mag=True, bin_s_mag = bin_sobel_mag, \n",
    "                                   s_ch=True,bin_s_ch=bin_s_channel,\n",
    "                                   r_ch=False,bin_r_ch=bin_r_channel)\n",
    "    else:\n",
    "        binary_or_img = binary_filters(s_x = True, bin_sx = bin_sobelx,\n",
    "                                   s_mag=True, bin_s_mag = bin_sobel_mag, \n",
    "                                   s_ch=True,bin_s_ch=bin_s_channel,\n",
    "                                   r_ch=True,bin_r_ch=bin_r_channel)\n",
    "    return binary_or_img,bin_sobelx,bin_s_channel,bin_r_channel,bin_sobel_mag\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "\n",
    "\n",
    "def corners_unwarp(img, nx, ny, mtx, dist):\n",
    "    offset = 100\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    ret, corners = cv2.findChessboardCorners(img, (nx,ny), None)\n",
    "\n",
    "    if ret == True: \n",
    "\n",
    "        src = np.float32([corners[0], corners[nx-1], corners[-1], corners[-nx]])\n",
    "\n",
    "        dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                          [img_size[0]-offset, img_size[1]-offset], [offset, img_size[1]-offset]])\n",
    "        \n",
    "        #warped, M, invM = warper(img, src, dst)\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        warped = cv2.warpPerspective(img,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return warped\n",
    "    else:\n",
    "        return 0,0\n",
    "\n",
    "def warper(img, src, dst):\n",
    "\n",
    "    # Compute and apply perpective transform\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    #warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_NEAREST)  # keep same size as input image\n",
    "    warped = cv2.warpPerspective(img,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "    invM = cv2.getPerspectiveTransform(dst,src)\n",
    "    \n",
    "    return warped, M, invM\n",
    "    \n",
    "\n",
    "def convert_to_gray(img,mpimgImread=True):\n",
    "    if (mpimgImread==True):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        #convert to three channels\n",
    "        gray = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)    \n",
    "        return gray\n",
    "    else:\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BRG2GRAY)\n",
    "    \n",
    "    \n",
    "def getWarpSrcPts(img):\n",
    "\n",
    "    x_offset_up = 550\n",
    "    x_offset_low = 170\n",
    "    y_offset_up = 250\n",
    "    y_car_hood = 30\n",
    "    #lower left corner of Trapezoid\n",
    "    P1 = (x_offset_low,img.shape[0]-y_car_hood)\n",
    "    #upper left corner of Trapezoid\n",
    "    P2 = (x_offset_up, img.shape[0]-y_offset_up) \n",
    "    #upper right corner of Trapezoid\n",
    "    P3 = (int(round(img.shape[1]-x_offset_up)), img.shape[0]-y_offset_up)\n",
    "    #lower right corner of Trapezoid\n",
    "    P4 = (img.shape[1]-x_offset_low,img.shape[0]-y_car_hood)\n",
    "    \n",
    "    return  np.float32([P3,P4,P1,P2]) \n",
    "\n",
    "def getWarpDstPts(img):\n",
    "\n",
    "    x_offset = 300\n",
    "    y_offset_up = 50\n",
    "    #lower left corner of Trapezoid\n",
    "    #P1 = (x_offset_low,img.shape[0])\n",
    "    #upper left corner of Trapezoid\n",
    "    #P2 = (x_offset_up, y_offset_up) \n",
    "    #upper right corner of Trapezoid\n",
    "    #P3 = (img.shape[1]-x_offset_up-10, y_offset_up)\n",
    "    #lower right corner of Trapezoid\n",
    "    #P4 = (img.shape[1]-x_offset_low,img.shape[0])\n",
    "\n",
    "    #lower left corner of Trapezoid\n",
    "    P1 = (x_offset,img.shape[0])\n",
    "    #upper left corner of Trapezoid\n",
    "    P2 = (x_offset, y_offset_up) \n",
    "    #upper right corner of Trapezoid\n",
    "    P3 = (img.shape[1]-x_offset, y_offset_up)\n",
    "    #lower right corner of Trapezoid\n",
    "    P4 = (img.shape[1]-x_offset,img.shape[0])    \n",
    "    \n",
    "    \n",
    "    return  np.float32([P3,P4,P1,P2])\n",
    "\n",
    "def merge_color_channels(img):\n",
    "\n",
    "    channel1 = img[:,:,0]\n",
    "    channel2 = img[:,:,1]\n",
    "    channel3 = img[:,:,2]\n",
    "    \n",
    "    binary_img = np.zeros_like(channel1)\n",
    "    binary_img[(channel1 > 0) | (channel2 > 0) | (channel3 > 0) ]=1\n",
    "\n",
    "    return binary_img\n",
    "\n",
    "def undistort_and_warp(img):\n",
    "    undist_img = undistort(img, mtx, dist)\n",
    "    \n",
    "    src = getWarpSrcPts(undist_img) \n",
    "    dst = getWarpDstPts(undist_img) \n",
    "\n",
    "    warped,M,invM = warper(undist_img, src, dst)    \n",
    "    \n",
    "\n",
    "    return warped,M,invM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the calibration process only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mtx, dist, rvecs, tvecs  = run_calibration_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing: undistort and warp chessboard images as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'camera_cal/calibration3.jpg'\n",
    "img1 = mpimg.imread(filename)\n",
    "\n",
    "imNum1 = filename.split('camera_cal/calibration')[1].split('.jpg')[0]\n",
    "\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "undistorted1= undistort(img1, mtx, dist)\n",
    "gray1 = convert_to_gray(undistorted1)\n",
    "top_down1 = corners_unwarp(gray1, nx, ny, mtx, dist)\n",
    "\n",
    "#open a second image with different nx and ny\n",
    "filename = 'camera_cal/calibration1.jpg'\n",
    "img2 = mpimg.imread(filename)\n",
    "\n",
    "imNum2 = filename.split('camera_cal/calibration')[1].split('.jpg')[0]\n",
    "       \n",
    "nx = 9\n",
    "ny = 5\n",
    "\n",
    "undistorted2 = undistort(img2, mtx, dist)\n",
    "gray2 = convert_to_gray(undistorted2)\n",
    "top_down2 = corners_unwarp(gray2, nx, ny, mtx, dist)\n",
    "\n",
    "\n",
    "f, ((ax1, ax2), (ax3,ax4),(ax5,ax6)) = plt.subplots(3,2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img1)\n",
    "ax1.set_title('Original calibration image {}'.format(imNum1), fontsize=10)\n",
    "ax3.imshow(undistorted1)\n",
    "ax3.set_title('Undistorted image {}'.format(imNum1), fontsize=10)\n",
    "ax5.imshow(top_down1)\n",
    "ax5.set_title('Undistorted and Warped  image {}'.format(imNum1), fontsize=10)\n",
    "\n",
    "ax2.imshow(img2)\n",
    "ax2.set_title('Original calibration image {}'.format(imNum2), fontsize=10)\n",
    "ax4.imshow(undistorted2)\n",
    "ax4.set_title('Undistorted image {}'.format(imNum2), fontsize=10)\n",
    "ax6.imshow(top_down2)\n",
    "ax6.set_title('Undistorted and Warped image {}'.format(imNum2), fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.05)\n",
    "\n",
    "f.savefig('output_images/undistort_warp_chessboard_examples.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing: undistort both road test images for validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undistorting straight line images\n",
    "test_img_1 = 'test_images/straight_lines1.jpg'\n",
    "test_img_2 = 'test_images/straight_lines2.jpg'\n",
    "#test_img_1 = 'camera_cal/calibration1.jpg' \n",
    "img1 = plt.imread(test_img_1)\n",
    "img2 = plt.imread(test_img_2)\n",
    "test_img_1_undistorted = undistort(img1, mtx, dist)\n",
    "test_img_2_undistorted = undistort(img2, mtx, dist)\n",
    "\n",
    "\n",
    "f, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2, 2, figsize=(18, 7))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img1)\n",
    "ax1.set_title('Original Image 1', fontsize=10)\n",
    "ax2.imshow(test_img_1_undistorted)\n",
    "ax2.set_title('Undistorted Image 1', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "ax3.imshow(img2)\n",
    "ax3.set_title('Original Image 2', fontsize=10)\n",
    "ax4.imshow(test_img_2_undistorted)\n",
    "ax4.set_title('Undistorted Image 2', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "plt.imsave('output_images/straight_lines1_undist.jpg',test_img_1_undistorted )\n",
    "plt.imsave('output_images/straight_lines2_undist.jpg',test_img_2_undistorted )\n",
    "# Save the full figure...\n",
    "f.savefig('output_images/straight_lines_undist.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different HLS and Sobel thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfilename1 = 'output_images/straight_lines1_undist.jpg'\\nimage1 = plt.imread(filename1)\\nresult11,result12BW,tmp = saturSobelRed(image1, s_thresh=(120, 255), sx_thresh=(10, 100),gauss_blur=True,gauss_k_size=3)\\nresult12,result12BW,tmp = saturSobelRed(image1, s_thresh=(150, 255), sx_thresh=(20, 100),gauss_blur=True,gauss_k_size=3)\\nresult13,result13BW,tmp = saturSobelRed(image1, s_thresh=(255, 255), sx_thresh=(40, 100),gauss_blur=True,gauss_k_size=3)\\n\\nfilename2 = 'output_images/straight_lines2_undist.jpg'\\nimage2 = plt.imread(filename2)\\nresult21,result21BW,tmp = saturSobelRed(image2, s_thresh=(120, 255), sx_thresh=(10, 100),gauss_blur=True,gauss_k_size=3)\\nresult22,result22BW ,tmp= saturSobelRed(image2, s_thresh=(150, 255), sx_thresh=(20, 100),gauss_blur=True,gauss_k_size=3)\\nresult23,result23BW ,tmp= saturSobelRed(image2, s_thresh=(255, 255), sx_thresh=(40, 100),gauss_blur=True,gauss_k_size=3)\\n\\n# Plot the result\\nf, ((ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2, figsize=(18, 7))\\nf.tight_layout()\\nax1.imshow(result11)\\nax1.set_title('Saturation and Sobel params set 1', fontsize=10)\\nax3.imshow(result12)\\nax3.set_title('Saturation and Sobel params set 2', fontsize=10)\\nplt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\\nax5.imshow(result13)\\nax5.set_title('Saturation and Sobel params set 3', fontsize=10)\\nplt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\\n\\nax2.imshow(result21)\\nax2.set_title('Saturation and Sobel params set 1', fontsize=10)\\nax4.imshow(result22)\\nax4.set_title('Saturation and Sobel params set 2', fontsize=10)\\nax6.imshow(result23)\\nax6.set_title('Saturation and Sobel params set 3', fontsize=10)\\nplt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "filename1 = 'output_images/straight_lines1_undist.jpg'\n",
    "image1 = plt.imread(filename1)\n",
    "result11,result12BW,tmp = saturSobelRed(image1, s_thresh=(120, 255), sx_thresh=(10, 100),gauss_blur=True,gauss_k_size=3)\n",
    "result12,result12BW,tmp = saturSobelRed(image1, s_thresh=(150, 255), sx_thresh=(20, 100),gauss_blur=True,gauss_k_size=3)\n",
    "result13,result13BW,tmp = saturSobelRed(image1, s_thresh=(255, 255), sx_thresh=(40, 100),gauss_blur=True,gauss_k_size=3)\n",
    "\n",
    "filename2 = 'output_images/straight_lines2_undist.jpg'\n",
    "image2 = plt.imread(filename2)\n",
    "result21,result21BW,tmp = saturSobelRed(image2, s_thresh=(120, 255), sx_thresh=(10, 100),gauss_blur=True,gauss_k_size=3)\n",
    "result22,result22BW ,tmp= saturSobelRed(image2, s_thresh=(150, 255), sx_thresh=(20, 100),gauss_blur=True,gauss_k_size=3)\n",
    "result23,result23BW ,tmp= saturSobelRed(image2, s_thresh=(255, 255), sx_thresh=(40, 100),gauss_blur=True,gauss_k_size=3)\n",
    "\n",
    "# Plot the result\n",
    "f, ((ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2, figsize=(18, 7))\n",
    "f.tight_layout()\n",
    "ax1.imshow(result11)\n",
    "ax1.set_title('Saturation and Sobel params set 1', fontsize=10)\n",
    "ax3.imshow(result12)\n",
    "ax3.set_title('Saturation and Sobel params set 2', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "ax5.imshow(result13)\n",
    "ax5.set_title('Saturation and Sobel params set 3', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "ax2.imshow(result21)\n",
    "ax2.set_title('Saturation and Sobel params set 1', fontsize=10)\n",
    "ax4.imshow(result22)\n",
    "ax4.set_title('Saturation and Sobel params set 2', fontsize=10)\n",
    "ax6.imshow(result23)\n",
    "ax6.set_title('Saturation and Sobel params set 3', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfilename1 = 'output_images/straight_lines1_undist.jpg'\\nimage1 = plt.imread(filename1)\\nresult11,result11BW,tmp = saturSobelRed(image1, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=3)\\nresult12,result12BW,tmp = saturSobelRed(image1, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=5)\\nresult13,result13BW,tmp = saturSobelRed(image1, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=15)\\n\\nfilename2 = 'output_images/straight_lines2_undist.jpg'\\nimage2 = plt.imread(filename2)\\nresult21,result21BW,tmp = saturSobelRed(image2, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=3)\\nresult22,result22BW ,tmp= saturSobelRed(image2, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=5)\\nresult23,result23BW,tmp = saturSobelRed(image2, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=15)\\n\\n# Plot the result\\nf, ((ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2, figsize=(18, 7))\\nf.tight_layout()\\nax1.imshow(result11)\\nax1.set_title('Saturation and Sobel params set 1', fontsize=10)\\nax3.imshow(result12)\\nax3.set_title('Saturation and Sobel params set 2', fontsize=10)\\nplt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\\nax5.imshow(result13)\\nax5.set_title('Saturation and Sobel params set 3', fontsize=10)\\nplt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\\n\\nax2.imshow(result21)\\nax2.set_title('Saturation and Sobel params set 1', fontsize=10)\\nax4.imshow(result22)\\nax4.set_title('Saturation and Sobel params set 2', fontsize=10)\\nax6.imshow(result23)\\nax6.set_title('Saturation and Sobel params set 3', fontsize=10)\\nplt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "filename1 = 'output_images/straight_lines1_undist.jpg'\n",
    "image1 = plt.imread(filename1)\n",
    "result11,result11BW,tmp = saturSobelRed(image1, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=3)\n",
    "result12,result12BW,tmp = saturSobelRed(image1, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=5)\n",
    "result13,result13BW,tmp = saturSobelRed(image1, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=15)\n",
    "\n",
    "filename2 = 'output_images/straight_lines2_undist.jpg'\n",
    "image2 = plt.imread(filename2)\n",
    "result21,result21BW,tmp = saturSobelRed(image2, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=3)\n",
    "result22,result22BW ,tmp= saturSobelRed(image2, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=5)\n",
    "result23,result23BW,tmp = saturSobelRed(image2, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=15)\n",
    "\n",
    "# Plot the result\n",
    "f, ((ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2, figsize=(18, 7))\n",
    "f.tight_layout()\n",
    "ax1.imshow(result11)\n",
    "ax1.set_title('Saturation and Sobel params set 1', fontsize=10)\n",
    "ax3.imshow(result12)\n",
    "ax3.set_title('Saturation and Sobel params set 2', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "ax5.imshow(result13)\n",
    "ax5.set_title('Saturation and Sobel params set 3', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "ax2.imshow(result21)\n",
    "ax2.set_title('Saturation and Sobel params set 1', fontsize=10)\n",
    "ax4.imshow(result22)\n",
    "ax4.set_title('Saturation and Sobel params set 2', fontsize=10)\n",
    "ax6.imshow(result23)\n",
    "ax6.set_title('Saturation and Sobel params set 3', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing perspective transform with color images of roads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename1 = 'output_images/straight_lines1_undist.jpg'\n",
    "image1 = plt.imread(filename1)\n",
    "src = getWarpSrcPts(image1) \n",
    "dst = getWarpDstPts(image1) \n",
    "\n",
    "warped1,M,invM = warper(image1, src, dst)\n",
    "plt.imsave('output_images/straight_lines1_warped.jpg',warped1)\n",
    "#left reference line warped image\n",
    "cv2.line(warped1, (dst[2][0], dst[2][1]), (dst[3][0], dst[3][1]), [0,255,0], 4)\n",
    "cv2.circle(warped1, (dst[2][0], dst[2][1]), 2, [0,255,0], 12)\n",
    "cv2.circle(warped1, (dst[3][0], dst[3][1]), 2, [0,255,0], 12)\n",
    "\n",
    "#right reference line warped image\n",
    "cv2.line(warped1, (dst[0][0], dst[0][1]), (dst[1][0], dst[1][1]), [255,0,0], 4)\n",
    "cv2.circle(warped1, (dst[0][0], dst[0][1]), 2, [255,0,0], 12)\n",
    "cv2.circle(warped1, (dst[1][0], dst[1][1]), 2, [255,0,0], 12)\n",
    "\n",
    "#left reference line original image\n",
    "cv2.line(image1, (src[2][0], src[2][1]), (src[3][0], src[3][1]), [0,255,0], 4) \n",
    "cv2.line(image1, (src[2][0], src[2][1]), (src[1][0], src[1][1]), [0,0,255], 4)\n",
    "cv2.line(image1, (src[3][0], src[3][1]), (src[0][0], src[0][1]), [0,0,255], 4) \n",
    "cv2.circle(image1, (src[2][0], src[2][1]), 2, [0,255,0], 12)\n",
    "cv2.circle(image1, (src[3][0], src[3][1]), 2, [0,255,0], 12)\n",
    "\n",
    "#right reference line original image\n",
    "cv2.line(image1, (src[0][0], src[0][1]), (src[1][0], src[1][1]), [255,0,0], 4)\n",
    "cv2.circle(image1, (src[0][0], src[0][1]), 2, [255,0,0], 12)\n",
    "cv2.circle(image1, (src[1][0], src[1][1]), 2, [255,0,0], 12)\n",
    "\n",
    "filename2 = 'output_images/straight_lines2_undist.jpg'\n",
    "image2 = plt.imread(filename2)\n",
    "src = getWarpSrcPts(image2) \n",
    "dst = getWarpDstPts(image2) \n",
    "\n",
    "warped2,M,invM = warper(image2, src, dst)\n",
    "\n",
    "plt.imsave('output_images/straight_lines2_warped.jpg',warped2)\n",
    "#left reference line warped image\n",
    "cv2.line(warped2, (dst[2][0], dst[2][1]), (dst[3][0], dst[3][1]), [0,255,0], 4)\n",
    "cv2.circle(warped2, (dst[2][0], dst[2][1]), 2, [0,255,0], 12)\n",
    "cv2.circle(warped2, (dst[3][0], dst[3][1]), 2, [0,255,0], 12)\n",
    "\n",
    "#right reference line warped image\n",
    "cv2.line(warped2, (dst[0][0], dst[0][1]), (dst[1][0], dst[1][1]), [255,0,0], 4)\n",
    "cv2.circle(warped2, (dst[0][0], dst[0][1]), 2, [255,0,0], 12)\n",
    "cv2.circle(warped2, (dst[1][0], dst[1][1]), 2, [255,0,0], 12)\n",
    "\n",
    "#left reference line original image\n",
    "cv2.line(image2, (src[2][0], src[2][1]), (src[3][0], src[3][1]), [0,255,0], 4) \n",
    "cv2.line(image2, (src[2][0], src[2][1]), (src[1][0], src[1][1]), [0,0,255], 4)\n",
    "cv2.line(image2, (src[3][0], src[3][1]), (src[0][0], src[0][1]), [0,0,255], 4) \n",
    "cv2.circle(image2, (src[2][0], src[2][1]), 2, [0,255,0], 12)\n",
    "cv2.circle(image2, (src[3][0], src[3][1]), 2, [0,255,0], 12)\n",
    "\n",
    "#right reference line original image\n",
    "cv2.line(image2, (src[0][0], src[0][1]), (src[1][0], src[1][1]), [255,0,0], 4)\n",
    "cv2.circle(image2, (src[0][0], src[0][1]), 2, [255,0,0], 12)\n",
    "cv2.circle(image2, (src[1][0], src[1][1]), 2, [255,0,0], 12)\n",
    "\n",
    "\n",
    "f, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2, 2, figsize=(18, 7))\n",
    "f.tight_layout()\n",
    "ax1.imshow(image1)\n",
    "ax1.set_title('Original image 1 with reference lines', fontsize=10)\n",
    "ax2.imshow(warped1)\n",
    "ax2.set_title('Img 1 Undistorted and warped', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "ax3.imshow(image2)\n",
    "ax3.set_title('Original image 2 with reference lines', fontsize=10)\n",
    "ax4.imshow(warped2)\n",
    "ax4.set_title('Img2 Undistorted and warped', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "# Save the full figure...\n",
    "f.savefig('output_images/warped_straight_lines.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply color, gradient, undistort and warp to straight lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfilename1 = 'output_images/straight_lines1_undist.jpg'\\n\\nimage1 = mpimg.imread(filename1)\\nresult1,result1BW = saturSobelRed(image1, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=5,gauss_blur=True,gauss_k_size=3)\\nsingleCh1 = merge_color_channels(result1)\\nsrc = getWarpSrcPts(singleCh1) \\ndst = getWarpDstPts(singleCh1) \\nwarped1,M,invM = warper(singleCh1, src, dst)\\n\\n\\nfilename2 = 'output_images/straight_lines2_undist.jpg'\\nimage2 = plt.imread(filename2)\\nresult2,result2BW = saturSobelRed(image2, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=5,gauss_blur=True,gauss_k_size=3)\\nsingleCh2 = merge_color_channels(result2)\\nsrc = getWarpSrcPts(singleCh2) \\ndst = getWarpDstPts(singleCh2) \\nwarped2,M,invM = warper(singleCh2, src, dst)\\n\\n\\nf, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2, 2, figsize=(18, 7))\\nf.tight_layout()\\nax1.imshow(result1)\\nax1.set_title('Img 1 thresholded', fontsize=10)\\nax2.imshow(warped1,cmap='gray')\\nax2.set_title('Img 1 binary warped after thresholds', fontsize=10)\\nax3.imshow(result2)\\nax3.set_title('Img2 thresholded', fontsize=10)\\nax4.imshow(warped2,cmap='gray')\\nax4.set_title('Img 2 binary warped after thresholds', fontsize=10)\\nplt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\\n\\n# Save the full figure...\\nf.savefig('output_images/thresholded_warped_straight_lines.jpg')\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "'''\n",
    "filename1 = 'output_images/straight_lines1_undist.jpg'\n",
    "\n",
    "image1 = mpimg.imread(filename1)\n",
    "result1,result1BW = saturSobelRed(image1, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=5,gauss_blur=True,gauss_k_size=3)\n",
    "singleCh1 = merge_color_channels(result1)\n",
    "src = getWarpSrcPts(singleCh1) \n",
    "dst = getWarpDstPts(singleCh1) \n",
    "warped1,M,invM = warper(singleCh1, src, dst)\n",
    "\n",
    "\n",
    "filename2 = 'output_images/straight_lines2_undist.jpg'\n",
    "image2 = plt.imread(filename2)\n",
    "result2,result2BW = saturSobelRed(image2, s_thresh=(150, 255), sx_thresh=(20, 100),kernelS=5,gauss_blur=True,gauss_k_size=3)\n",
    "singleCh2 = merge_color_channels(result2)\n",
    "src = getWarpSrcPts(singleCh2) \n",
    "dst = getWarpDstPts(singleCh2) \n",
    "warped2,M,invM = warper(singleCh2, src, dst)\n",
    "\n",
    "\n",
    "f, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2, 2, figsize=(18, 7))\n",
    "f.tight_layout()\n",
    "ax1.imshow(result1)\n",
    "ax1.set_title('Img 1 thresholded', fontsize=10)\n",
    "ax2.imshow(warped1,cmap='gray')\n",
    "ax2.set_title('Img 1 binary warped after thresholds', fontsize=10)\n",
    "ax3.imshow(result2)\n",
    "ax3.set_title('Img2 thresholded', fontsize=10)\n",
    "ax4.imshow(warped2,cmap='gray')\n",
    "ax4.set_title('Img 2 binary warped after thresholds', fontsize=10)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "# Save the full figure...\n",
    "f.savefig('output_images/thresholded_warped_straight_lines.jpg')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply color, gradient, undistort and warp to other test images (curved lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def binary_compare(bin_sobelx,sobelx_bin):\n",
    "    w = sobelx_bin.shape[1]\n",
    "    h = sobelx_bin.shape[0]\n",
    "    for x in range(0,w-1):\n",
    "        for y in range(0,h-1):\n",
    "            if sobelx_bin[y,x] != bin_sobelx[y,x]:\n",
    "                print(\"something wrong here: {}{}\".format(x,y))\n",
    "\n",
    "images = glob.glob('test_images/test*.jpg')    \n",
    "\n",
    "for im in images:\n",
    "    imNum = im.split('test_images/test')[1].split('.jpg')[0]\n",
    "    image = mpimg.imread(im)\n",
    "\n",
    "    warped,M,invM = undistort_and_warp(image)\n",
    "    binary_or_img,bin_sobelx,bin_s_channel,bin_r_channel,bin_sobel_mag = colors_and_gradients(warped)\n",
    "\n",
    "    \n",
    "    #convert the image to three channel for vis purposes\n",
    "    binary_or_img_color = cv2.cvtColor(binary_or_img, cv2.COLOR_GRAY2RGB) *255\n",
    "    #left reference line warped image\n",
    "    cv2.line(binary_or_img_color, (dst[2][0], dst[2][1]), (dst[3][0], dst[3][1]), [0,255,0], 4)\n",
    "    #right reference line warped image\n",
    "    cv2.line(binary_or_img_color, (dst[0][0], dst[0][1]), (dst[1][0], dst[1][1]), [255,0,0], 4)    \n",
    "    \n",
    "    f, ((ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3, 2, figsize=(18, 7))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(warped)\n",
    "    ax1.set_title('Warped test image {}'.format(imNum), fontsize=10)\n",
    "    ax2.imshow(cv2.cvtColor(bin_s_channel, cv2.COLOR_GRAY2RGB) *255)\n",
    "    ax2.set_title('Binary saturation channel', fontsize=10)\n",
    "    ax3.imshow(cv2.cvtColor(bin_r_channel, cv2.COLOR_GRAY2RGB) *255)\n",
    "    ax3.set_title('Binary red channel', fontsize=10)\n",
    "    ax4.imshow(cv2.cvtColor(bin_sobelx, cv2.COLOR_GRAY2RGB) *255)\n",
    "    ax4.set_title('Binary sobelx channel', fontsize=10)\n",
    "    ax5.imshow(cv2.cvtColor(bin_sobel_mag, cv2.COLOR_GRAY2RGB) *255)\n",
    "    ax5.set_title('Binary sobel magnitude (x and y) channel', fontsize=10)\n",
    "    ax6.imshow(binary_or_img_color)\n",
    "    ax6.set_title('Binary OR of all channels above', fontsize=10)    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding lane pixels with sliding windows and polynoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly_lines(img_shape, left_fit,right_fit):\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    \n",
    "    try:           \n",
    "        right_fitx = ploty**2*right_fit[0] + ploty*right_fit[1] + right_fit[2]\n",
    "        left_fitx = ploty**2*left_fit[0] + ploty*left_fit[1] + left_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "\n",
    "    return left_fitx, right_fitx, ploty\n",
    "\n",
    "def fit_poly(leftx, lefty, rightx, righty):\n",
    "    ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    return left_fit, right_fit\n",
    "\n",
    "\n",
    "def lane_search_with_windows(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit,right_fit = fit_poly(leftx, lefty, rightx, righty)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    imsize = (binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    left_fitx, right_fitx, ploty =  build_poly_lines(binary_warped.shape, left_fit,right_fit)\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return out_img,left_fitx, right_fitx, ploty,left_fit, right_fit\n",
    "\n",
    "     \n",
    "def lane_search_around_poly(binary_warped,left_fit_prev,right_fit_prev):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    \n",
    "    left_lane_inds = ((nonzerox <= ((nonzeroy**2)*left_fit_prev[0]+nonzeroy*left_fit_prev[1]+left_fit_prev[2])+margin)&\n",
    "                      (nonzerox > ((nonzeroy**2)*left_fit_prev[0]+nonzeroy*left_fit_prev[1]+left_fit_prev[2])-margin))\n",
    "    right_lane_inds = ((nonzerox <= ((nonzeroy**2)*right_fit_prev[0]+nonzeroy*right_fit_prev[1]+right_fit_prev[2])+margin)&\n",
    "                      (nonzerox > ((nonzeroy**2)*right_fit_prev[0]+nonzeroy*right_fit_prev[1]+right_fit_prev[2])-margin))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fit, right_fit = fit_poly(leftx, lefty, rightx, righty)\n",
    "\n",
    "    #build lines\n",
    "    left_fitx, right_fitx, ploty = build_poly_lines(binary_warped.shape, left_fit,right_fit)\n",
    "\n",
    "    #left_fitx, right_fitx, ploty = fit_poly_old(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    \n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    \n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    \n",
    "    return result,left_fitx, right_fitx, ploty,left_fit, right_fit\n",
    "\n",
    "\n",
    "def measure_curvature_real(ym_per_pix,xm_per_pix,ploty,left_fit_cr,right_fit_cr):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ##### TO-DO: Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    #327 and 971 are starting points\n",
    "    \n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        \n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin  \n",
    "        win_xleft_high = leftx_current + margin  \n",
    "        \n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzerox >= win_xleft_low) & (nonzerox <win_xleft_high) &\n",
    "        (nonzeroy>=win_y_low) & (nonzeroy <win_y_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzerox >=win_xright_low)&(nonzerox <win_xright_high)&\n",
    "                           (nonzeroy>=win_y_low) & (nonzeroy <win_y_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def car_lanes_offset(left,right,imwidth):\n",
    "    imMid = imwidth//2\n",
    "    laneMid = left+(right-left)//2\n",
    "    return laneMid-imMid\n",
    "\n",
    "def fill_driving_space(grayImg,left_fitx, right_fitx, ploty):\n",
    "\n",
    "    h, w = grayImg.shape[:2]\n",
    "\n",
    "    pointsL = np.array([[[xi, yi]] for xi, yi in zip(left_fitx, ploty) if (0<=xi<w and 0<=yi<h)]).astype(np.int32)\n",
    "    pointsR = np.array([[[xi, yi]] for xi, yi in zip(right_fitx, ploty) if (0<=xi<w and 0<=yi<h)]).astype(np.int32)\n",
    "    pointsR = np.flipud(pointsR)\n",
    "    points = np.concatenate((pointsL, pointsR))\n",
    "\n",
    "    driving_space = grayImg.copy()\n",
    "    driving_space = cv2.cvtColor(driving_space,cv2.COLOR_GRAY2RGB)\n",
    "    #color driving space\n",
    "    cv2.fillPoly(driving_space, [points], color=[0,255,0])\n",
    "    #add left line overlay\n",
    "    cv2.polylines(driving_space, [pointsL], color=[255,0,0], isClosed = True,thickness = 20)\n",
    "    #add right line overlay\n",
    "    cv2.polylines(driving_space, [pointsR], color=[255,0,0], isClosed = True,thickness = 20)   \n",
    "    \n",
    "    return driving_space\n",
    "\n",
    "# Polynomial fit values from the previous frame\n",
    "# Make sure to grab the actual values from the previous step in your project!\n",
    "#left_fit_prev = np.array([ 2.13935315e-04, -3.77507980e-01,  4.76902175e+02])\n",
    "#right_fit_prev = np.array([4.17622148e-04, -4.93848953e-01,  1.11806170e+03])\n",
    "\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing pipeline on warped test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giorgio/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob('test_images/test*.jpg')    \n",
    "\n",
    "for im in images:\n",
    "    imNum = im.split('test_images/test')[1].split('.jpg')[0]\n",
    "\n",
    "    image = plt.imread(im)\n",
    "\n",
    "    warped,M,invM = undistort_and_warp(image)\n",
    "    binary_or_img,bin_sobelx,bin_s_channel,bin_r_channel,bin_sobel_mag = colors_and_gradients(warped)\n",
    "    \n",
    "\n",
    "    #result,left_fitx, right_fitx, ploty,left_fit, right_fit = lane_search_around_poly(binary_warped,left_fit_prev,right_fit_prev))\n",
    "    lineImg1,left_fitx, right_fitx, ploty,left_fit, right_fit = lane_search_with_windows(binary_or_img)\n",
    "    \n",
    "    \n",
    "    #print(left_fit.shape,left_fit_cr.shape)\n",
    "    # Calculate the radius of curvature in meters for both lane lines\n",
    "    leftcurv, rightcurv = measure_curvature_real(ym_per_pix,xm_per_pix,ploty,left_fit,right_fit)\n",
    "    car_offset = car_lanes_offset(left_fitx[-1],right_fitx[-1],lineImg1.shape[1])\n",
    "    s = \"Left curv:{:.2f}[m] \\nRight curv:{:.2f}[m]\\nCar offset:{:.2f}[m]\".format(leftcurv,rightcurv,car_offset*xm_per_pix)\n",
    "    x = 520\n",
    "    y = 100\n",
    "    \n",
    "   \n",
    "    f, ((ax1,ax2)) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(warped)\n",
    "    cv2.imwrite(\"test%s.jpg\" % imNum, warped)\n",
    "    ax1.set_title('Warped result test image {}'.format(imNum),  fontsize=10)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ax2.imshow(lineImg1)\n",
    "    ax2.text(x, y, s, fontsize=10, color='white')\n",
    "    ax2.set_title('Detected lanes with\\n corresponding polynom drawn', fontsize=10)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def warped_binary(image):\n",
    "    \n",
    "    warped,M,invM = undistort_and_warp(image)\n",
    "    binary_or_img,bin_sobelx,bin_s_channel,bin_r_channel,bin_sobel_mag = colors_and_gradients(warped)\n",
    "    \n",
    "    return warped,M,invM,binary_or_img\n",
    "\n",
    "\n",
    "def add_curv_offset_text(merged,leftcurv,rightcurv):\n",
    "    \n",
    "    car_offset = car_lanes_offset(left_fitx[-1],right_fitx[-1],image.shape[1])\n",
    "\n",
    "    leftTxt = \"Left curv:{:.2f}[m]\".format(leftcurv)    \n",
    "    rigtTxt = \"Right curv:{:.2f}[m]\".format(rightcurv)\n",
    "    offsetTxt = \"Car offset:{:.2f}[m]\".format(car_offset*xm_per_pix)\n",
    "\n",
    "    position = (400,100)\n",
    "    cv2.putText(\n",
    "         merged, #numpy array on which text is written\n",
    "         leftTxt, #text\n",
    "         position, #position at which writing has to start\n",
    "         cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "         1, #font size\n",
    "         (255, 255, 255, 255), #font color\n",
    "         3) #font stroke \n",
    "    position = (400,140)\n",
    "    cv2.putText(\n",
    "         merged, #numpy array on which text is written\n",
    "         rigtTxt, #text\n",
    "         position, #position at which writing has to start\n",
    "         cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "         1, #font size\n",
    "         (255, 255, 255, 255), #font color\n",
    "         3) #font stroke \n",
    "    position = (400,180)\n",
    "    cv2.putText(\n",
    "         merged, #numpy array on which text is written\n",
    "         offsetTxt, #text\n",
    "         position, #position at which writing has to start\n",
    "         cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "         1, #font size\n",
    "         (255, 255, 255, 255), #font color\n",
    "         3) #font stroke   \n",
    "\n",
    "\n",
    "\n",
    "def process_frame(image):\n",
    "    global LinesRingBuffer\n",
    "    \n",
    "    warped,M,invM,binary_warped = warped_binary(image)\n",
    "\n",
    "    valid_l_fit_x = None\n",
    "    valid_l_cr = None\n",
    "    valid_r_fit_x = None\n",
    "    valid_r_cr = None\n",
    "    \n",
    "    if LinesRingBuffer.isFull():\n",
    "        print(\"enough lines for averaging and searching\")\n",
    "        #get the last poly values (averaged across the buffer)\n",
    "        \n",
    "        lines = LinesRingBuffer.data\n",
    "        left_avg_coeffs,right_avg_coeffs = averaging_poly(lines) \n",
    "        #left_fitx, right_fitx, ploty = build_poly_lines(binary_warped.shape,left_avg_coeffs,right_avg_coeffs) \n",
    "        \n",
    "        #use the poly coeffs from last line to search new lines\n",
    "        result,left_fitx, right_fitx, ploty,left_fit, right_fit = lane_search_around_poly(binary_warped,left_avg_coeffs,right_avg_coeffs)\n",
    "        \n",
    "        #if new line is detected within the margin, append it to the line buffer and use it\n",
    "        \n",
    "        #else empty the buffer, search line using sliding windows and append it\n",
    "        \n",
    "        result,valid_l_fit_x, valid_r_fit_x, ploty,left_fit, right_fit = lane_search_with_windows(binary_warped)\n",
    "        valid_l_cr, valid_r_cr = measure_curvature_real(ym_per_pix,xm_per_pix,ploty,left_fit,right_fit)\n",
    "        left=Line()\n",
    "        right=Line()\n",
    "        left.setLatestFitx(valid_l_fit_x)\n",
    "        left.setLatestFit(left_fit)\n",
    "        left.setCurvature(valid_l_cr)\n",
    "        left.setDetectedFlag(True)\n",
    "        right.setLatestFitx(valid_r_fit_x)\n",
    "        right.setLatestFit(right_fit)\n",
    "        right.setCurvature(valid_r_cr)\n",
    "        right.setDetectedFlag(True)\n",
    "\n",
    "        LinesRingBuffer.append((left,right))\n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        #fill the buffer with lines detected with the sliding windows method\n",
    "        result,valid_l_fit_x, valid_r_fit_x, ploty,left_fit, right_fit = lane_search_with_windows(binary_warped)\n",
    "        valid_l_cr, valid_r_cr = measure_curvature_real(ym_per_pix,xm_per_pix,ploty,left_fit,right_fit)\n",
    "        left=Line()\n",
    "        right=Line()\n",
    "        left.setLatestFitx(valid_l_fit_x)\n",
    "        left.setLatestFit(left_fit)\n",
    "        left.setCurvature(valid_l_cr)\n",
    "        left.setDetectedFlag(True)\n",
    "        right.setLatestFitx(valid_r_fit_x)\n",
    "        right.setLatestFit(right_fit)\n",
    "        right.setCurvature(valid_r_cr)\n",
    "        right.setDetectedFlag(True)\n",
    "\n",
    "        LinesRingBuffer.append((left,right)) \n",
    "\n",
    " \n",
    "        \n",
    "    \n",
    "    #lineImg1,left_fitx, right_fitx, ploty,left_fit, right_fit = lane_search_with_windows(binary)\n",
    "    #lineImg1,left_fitx, right_fitx, ploty,left_fit, right_fit = lane_search_with_windows(binary)\n",
    "       \n",
    "    \n",
    "    warpedGray = cv2.cvtColor(warped,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    driving_space = fill_driving_space(warpedGray,valid_l_fit_x, right_fitx, ploty)\n",
    "    img_size = (driving_space.shape[1], driving_space.shape[0])\n",
    "    unwarped = cv2.warpPerspective(driving_space,invM,img_size,flags=cv2.INTER_LINEAR)    \n",
    "    merged = cv2.addWeighted(image, 1, unwarped, 0.3, 0)\n",
    "    add_curv_offset_text(merged,valid_l_cr,valid_r_cr)\n",
    "    return merged\n",
    "\n",
    "\n",
    "class RingBuffer:\n",
    "    \"\"\" class that implements a not-yet-full buffer \n",
    "    source: https://www.oreilly.com/library/view/python-cookbook/0596001673/ch05s19.html\"\"\"\n",
    "    \n",
    "    def __init__(self,size_max):\n",
    "        self.max = size_max\n",
    "        self.data = []\n",
    "        self.full = False\n",
    "        \n",
    "    class __Full:\n",
    "        \"\"\" class that implements a full buffer \"\"\"\n",
    "        def append(self, x):\n",
    "            \"\"\" Append an element overwriting the oldest one. \"\"\"\n",
    "            self.data[self.cur] = x\n",
    "            self.cur = (self.cur+1) % self.max\n",
    "        \n",
    "        def isFull(self):\n",
    "            return self.full    \n",
    "        \n",
    "        def get(self):\n",
    "            \"\"\" return list of elements in correct order \"\"\"\n",
    "            return self.data[self.cur:]+self.data[:self.cur]\n",
    "\n",
    "    def append(self,x):\n",
    "        \"\"\"append an element at the end of the buffer\"\"\"\n",
    "        self.data.append(x)\n",
    "        if len(self.data) == self.max:\n",
    "            self.full = True\n",
    "            self.cur = 0\n",
    "            \n",
    "            # Permanently change self's class from non-full to full\n",
    "            self.__class__ = self.__Full\n",
    "    \n",
    "    def isFull(self):\n",
    "        return self.full\n",
    "\n",
    "    def get(self):\n",
    "        \"\"\" Return a list of elements from the oldest to the newest. \"\"\"\n",
    "        return self.data\n",
    " \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " def averaging_poly(lines):\n",
    "    \n",
    "    left_coeffs = []\n",
    "    avg_left = []\n",
    "    right_coeffs = []\n",
    "    avg_right = []\n",
    "    \n",
    "    for l,r in lines:\n",
    "        left_coeffs.append(l.getLatestFit())\n",
    "        right_coeffs.append(r.getLatestFit())\n",
    "\n",
    "    avg_left = np.mean(np.stack([left_coeffs]), axis=0)\n",
    "    avg_right = np.mean(np.stack([right_coeffs]), axis=0)\n",
    "\n",
    "    return avg_left, avg_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "\n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "    \n",
    "    def setDetectedFlag(self, flag):\n",
    "        self.detected = flag\n",
    "        \n",
    "    def getDetectedFlag(self):\n",
    "        return self.detected\n",
    "        \n",
    "    def setLatestFitx(self,fitx):\n",
    "        self.recent_xfitted = fitx\n",
    "        \n",
    "    def getLatestFitx(self):\n",
    "        return self.recent_xfitted \n",
    "    \n",
    "    def setLatestFit(self,fit_coeffs):\n",
    "        self.current_fit = fit_coeffs\n",
    "        \n",
    "    def getLatestFit(self):\n",
    "        return self.current_fit     \n",
    "\n",
    "    def setCurvature(self,curv):\n",
    "        self.radius_of_curvature = curv\n",
    "        \n",
    "    def getCurvature(self):\n",
    "        return self.radius_of_curvature  \n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'right_fitx' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fa2f548ffdf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#clip1 = VideoFileClip('challenge_video.mp4')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clip.write_videofile(output, audio=False)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mfl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[1;32m    489\u001b[0m         \u001b[0mapply_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_to\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mfl\u001b[0;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-177>\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \"\"\"\n\u001b[1;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moutplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-127>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[1;32m    489\u001b[0m         \u001b[0mapply_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_to\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f48a2c2b3174>\u001b[0m in \u001b[0;36mprocess_frame\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mwarpedGray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mdriving_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_driving_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarpedGray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_l_fit_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdriving_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriving_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0munwarped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarpPerspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriving_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minvM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'right_fitx' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "LinesRingBuffer = RingBuffer(5)\n",
    "output='output.mp4'\n",
    "clip1 = VideoFileClip('project_video.mp4')\n",
    "#clip1 = VideoFileClip('challenge_video.mp4')\n",
    "\n",
    "clip = clip1.fl_image(process_frame).subclip(0,.5)\n",
    "%time clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "#Video('project_video.mp4')\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src='output.mp4'>\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
